# Training configuration for Qwen3 Encoder-Decoder
# Usage: python scripts/train.py --config configs/training_config.yaml

model:
  model_name_or_path: "Qwen/Qwen3-0.6B"
  tokenizer_name_or_path: null  # Uses model_name_or_path if null
  num_sentinel_tokens: 100
  use_flash_attention: true

data:
  dataset_name: "HuggingFaceFW/fineweb-edu"
  dataset_config: null
  text_column: "text"
  streaming: true
  max_seq_length: 8192
  max_encoder_length: 4096
  max_decoder_length: 2048
  # UL2_5 options (uses UL25Config.recommended() denoiser mixture)
  ul2_length_adaptive: false
  ul2_boundary_snapping: false
  ul2_curriculum_start: null
  ul2_curriculum_end: null
  preprocessing_num_workers: 4
  shuffle_buffer_size: 10000
  dataloader_pin_memory: true
  dataloader_prefetch_factor: 2
  dataloader_persistent_workers: true
  dataloader_collate_on_cpu: true

training:
  # Batch size (effective = per_device * num_gpus * gradient_accumulation)
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 8

  # Optimization
  learning_rate: 2.0e-4
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0

  # Schedule
  num_train_steps: 100000
  warmup_steps: 1000
  lr_scheduler_type: "cosine"

  # Precision (bf16 only)
  bf16: true

  # GPU Optimizations
  use_tf32: true  # TF32 for Ampere+ (up to 3x faster matmuls)
  use_liger_kernels: true  # Liger optimized RMSNorm + SwiGLU MLP
  use_cut_cross_entropy: true  # Apple CCE (24GB -> 1MB loss memory)
  torch_compile: false  # Optional, 10-20% speedup, slower startup
  use_fused_adamw: true  # Use CUDA fused AdamW (faster)

  # Checkpointing
  save_steps: 1000
  save_total_limit: 5

  # Evaluation
  eval_steps: 500
  eval_samples: 1000

  # Logging
  logging_steps: 10
  report_to: ["wandb", "tensorboard"]

  # Reproducibility
  seed: 42

infra:
  output_dir: "./output"
  logging_dir: "./logs"
  distributed_type: "fsdp"
  fsdp_sharding_strategy: "FULL_SHARD"
  fsdp_activation_checkpointing: true
  fsdp_cpu_offload: false
  deepspeed_config: null
  num_gpus: 8
  wandb_project: "qwen3-encoder-decoder"
  wandb_entity: null
  wandb_run_name: null
  wandb_watch: "gradients"  # Log gradient histograms
  wandb_log_model: false
  wandb_tags: ["qwen3-encdec", "ul2", "t5gemma2"]
